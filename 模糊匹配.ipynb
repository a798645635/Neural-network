{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import os\n",
    "from fuzzywuzzy import fuzz, process\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建df1\n",
    "data1 = {\n",
    "    'Name': ['Tom', 'Nick', 'John', 'Peter'],\n",
    "    'Age': [20, 21, 19, 18],\n",
    "    'Subject': ['Math', 'Physics', 'Chemistry', 'Biology'],\n",
    "    'Score': [80, 90, 78, 88]\n",
    "}\n",
    "df1 = pd.DataFrame(data1)\n",
    "df1 = df1.astype(str)\n",
    "# 创建df2_clean_clean_clean_clean_clean_clean_clean，它包含与df1类似但带有拼写错误或不准确的姓名、学科\n",
    "data2 = {\n",
    "    'Name': ['tome', 'Nic', 'Johne', 'Pete'],\n",
    "    'Age': [20, 21, 19, 18],\n",
    "    'Subject': ['Maths', 'Physic', 'Chem', 'Bio'],\n",
    "    'Score': [80.00, 90, 78, 88]\n",
    "}\n",
    "df2 = pd.DataFrame(data2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tome</td>\n",
       "      <td>20</td>\n",
       "      <td>Maths</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nic</td>\n",
       "      <td>21</td>\n",
       "      <td>Physic</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Johne</td>\n",
       "      <td>19</td>\n",
       "      <td>Chem</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pete</td>\n",
       "      <td>18</td>\n",
       "      <td>Bio</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name Age Subject Score\n",
       "0   Tome  20   Maths  80.0\n",
       "1    Nic  21  Physic  90.0\n",
       "2  Johne  19    Chem  78.0\n",
       "3   Pete  18     Bio  88.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_dataframe(df, capitalize_columns=[],capitalize_name=True):\n",
    "\n",
    "    df_clean = df.copy()\n",
    "    # 将所有列转换为字符串类型\n",
    "    df_clean = df_clean.astype(str)\n",
    "\n",
    "    # 移除所有列中的空格\n",
    "    for col in df.columns:\n",
    "        df_clean[col] = df_clean[col].str.replace(' ', '')\n",
    "    \n",
    "    # 将指定的列的首字母转换为大写\n",
    "    if capitalize_name:\n",
    "        for col in capitalize_columns:\n",
    "            if col in df.columns:\n",
    "                df_clean[col] = df_clean[col].str.title()\n",
    "                # df_clean[col] = df_clean[col].str.upper()\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "# df2_clean=df2[[ '标准',]].drop_duplicates()\n",
    "df2_clean = clean_dataframe(df2, capitalize_columns=['Name'])\n",
    "df2_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_lines = []\n",
    "output_lines.append(\"标准姓名列\")\n",
    "changed_cells = []\n",
    "\n",
    "name_col_num = df2_clean.columns.get_loc('Name')\n",
    "\n",
    "# 遍历df2_clean的每一行\n",
    "for index, row in df2_clean.iterrows():\n",
    "    if row['Name'] not in df1['Name'].unique():\n",
    "        closest_matches = process.extract(row['Name'], df1['Name'].unique(), limit=3)\n",
    "        original_value = row['Name']\n",
    "        replaced_value = closest_matches[0][0]\n",
    "        \n",
    "        # 如果最接近的匹配的得分大于等于90，那么就替换相应的值\n",
    "        if closest_matches[0][1] >= 50:\n",
    "            df2_clean.at[index, 'Name'] = replaced_value\n",
    "            changed_cells.append((index, name_col_num))\n",
    "            output_lines.append(f\"原始值: {original_value}, 替换值: {replaced_value} 待选列表：\")\n",
    "            for i, match in enumerate(closest_matches):\n",
    "                output_lines.append(f\"{i+1}: {match[0]}\")\n",
    "            output_lines.append(\" \")\n",
    "        elif closest_matches[0][1] <= 50:\n",
    "            changed_cells.append((index, name_col_num))\n",
    "            output_lines.append(f\"原始值: {original_value}, 在之前的数据库中未找到.\")\n",
    "            output_lines.append(\" \")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_Subject(df1, df2, df1_column, df2_column, df1_match1, df1_match2):\n",
    "    \"\"\"\n",
    "    df1:待清洗dataframe\n",
    "    df1_match1, df1_match2：模糊匹配的列\n",
    "    df1_column, df2_column：需匹配的列\n",
    "    df2：标准dataframe\n",
    "    df1_match1, df1_match2\n",
    "    \"\"\"\n",
    "    output_lines.append(df2_column+\"列\")\n",
    "    changed_cells_col_num = df1.columns.get_loc(df1_column)\n",
    "    for index, row in df1.iterrows():\n",
    "        if row[df1_column] not in df2[df2_column].unique():\n",
    "            # matching_rows = df2[(df2['标准'] == row[df1_match1]) & (df2['标准'] == row[df1_match2])]\n",
    "            matching_rows = df2[(df2[df1_match1] == row[df1_match1]) & (df2[df1_match2] == row[df1_match2])]\n",
    "            # 使用fuzz.ratio找出df2中最像的三个值\n",
    "            closest_matches = process.extract(row[df1_column], matching_rows[df2_column].unique(), limit=3)\n",
    "            output_lines.append(f\"原始值 '{row[df1_column]}' 需要替换:\")\n",
    "            if not closest_matches:  # 添加这行代码来判断closest_matches是否为空\n",
    "                output_lines.append(f\"Value '{row[df1_column]}' 但在原数据库中未找到对应的值\")\n",
    "                output_lines.append(\" \")\n",
    "                changed_cells.append((index, changed_cells_col_num))\n",
    "                continue\n",
    "            replaced_value = closest_matches[0][0]\n",
    "            if closest_matches[0][1] >= 90:\n",
    "                output_lines.append(f\"原始值: {row[df1_column]}, 替换值: {replaced_value}\")\n",
    "                df1.at[index, df1_column] = replaced_value\n",
    "                changed_cells.append((index, changed_cells_col_num))\n",
    "                for i, match in enumerate(closest_matches):           \n",
    "                    #print(\"原始表格\" + tabulate(pd.DataFrame(row).T, headers='keys', tablefmt='psql', showindex=False))\n",
    "                    # output_lines.append(f\"Value '{row[df1_column]}' 不在原数据库中，需要替换:\")\n",
    "                    output_lines.append(f\"{i+1}: {match[0]}\")\n",
    "                    match_row = matching_rows.loc[matching_rows[df2_column] == match[0]]\n",
    "                output_lines.append(match_row.to_string(index=False))\n",
    "                output_lines.append(\" \")\n",
    "            elif closest_matches[0][1] <= 90:\n",
    "                changed_cells.append((index, changed_cells_col_num))\n",
    "                output_lines.append(f\"原始值: {row[df1_column]}, 在之前的数据库中未找到.\")\n",
    "                output_lines.append(\" \")\n",
    "                \n",
    "\n",
    "    return df1\n",
    "df2_clean=match_Subject(df2_clean, df1, df1_column='Subject', df2_column='Subject',df1_match1='Name', df1_match2='Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_cells_red = []\n",
    "def mark_unmatched_cells(changed_cells_red,df1, df2_clean,col,df1_match1,df1_match2):\n",
    "    Form_col_num = df2_clean.columns.get_loc(col)\n",
    "    for index, row in df2_clean.iterrows():\n",
    "        matching_rows = df1[(df1[df1_match1] == row[df1_match1]) & (df1[df1_match2] == row[df1_match2])]\n",
    "        if row[col] not in matching_rows[col].unique():\n",
    "            changed_cells_red.append((index, Form_col_num))\n",
    "    return changed_cells_red\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('修改日志.txt', 'w')\n",
    "\n",
    "# 循环遍历列表并写入文件\n",
    "for item in output_lines:\n",
    "    file.write(\"%s\\n\" % item)\n",
    "\n",
    "# 关闭文件\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "\n",
    "# 创建新的工作簿\n",
    "wb = Workbook()\n",
    "\n",
    "# 选择活动工作表\n",
    "sheet = wb.active\n",
    "\n",
    "# 定义填充颜色\n",
    "fill = PatternFill(start_color=\"FFFF00\", end_color=\"FFFF00\", fill_type = \"solid\")\n",
    "for cell in changed_cells :\n",
    "    sheet.cell(row=cell[0]+2, column=cell[1]+1).fill = fill\n",
    "\n",
    "fill = PatternFill(start_color=\"FFB6C1\", end_color=\"FFB6C1\", fill_type=\"solid\")\n",
    "for cell in changed_cells_red  :\n",
    "    sheet.cell(row=cell[0]+2, column=cell[1]+1).fill = fill\n",
    "\n",
    "\n",
    "# 保存到文件\n",
    "wb.save(\"colored_cells.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matched_df()：\n",
    "\n",
    "    # 初始化一个空的DataFrame来存储找到的行\n",
    "    matched_df = pd.DataFrame()\n",
    "    highest_ratio_df = pd.DataFrame()  # 新建一个DataFrame用于存储每个min1对应的fuzz_ratio最高的行\n",
    "\n",
    "    for index, row in df2_clean.iterrows():\n",
    "\n",
    "        #筛选防止数据过多\n",
    "        matching_rows = df1[(df1['Name'] == row['Name']) ]\n",
    "        a_val = row['1']\n",
    "        b_val = row['2']\n",
    "        c_val = row['3']\n",
    "        d_val = row['4']\n",
    "\n",
    "        max_ratio = -1  # 初始化一个变量用于记录最大的fuzz_ratio\n",
    "        max_ratio_row = None  # 初始化一个变量用于记录fuzz_ratio最大的行\n",
    "        temp_df = pd.DataFrame()\n",
    "        # 创建一个新的DataFrame来保存本次循环的数据\n",
    "        isStandardProductionCompanyExists = False\n",
    "        for idx, r in matching_rows.iterrows():\n",
    "            if r['标准学科'] == row[\"学科\"]:\n",
    "                r['标准学科匹配'] = 1\n",
    "                isStandardProductionCompanyExists = True\n",
    "\n",
    "            fuzz_value =(fuzz.ratio(r['标准名1'], a_val) + \\\n",
    "                        fuzz.ratio(r['标准名2'], b_val)+   \\\n",
    "                        fuzz.ratio(r['标准名3'], c_val)+   \\\n",
    "                        fuzz.ratio(r['标准名4'], d_val)   )/4\n",
    "            \n",
    "            r['fuzz_ratio'] = fuzz_value\n",
    "            r['index_id'] = index\n",
    "            temp_df = temp_df.append(r)\n",
    "\n",
    "            # 如果当前的fuzz_ratio大于已知的最大值，则更新最大值和对应的行\n",
    "            if fuzz_value > max_ratio:\n",
    "                max_ratio = fuzz_value\n",
    "                max_ratio_row = r\n",
    "        if isStandardProductionCompanyExists ==False:\n",
    "            matching_Manufacturer_rows = df1[(df1['标准学科'] == row['学科']) ]\n",
    "            matching_Manufacturer_rows = matching_Manufacturer_rows.assign(标准学科匹配=1)\n",
    "            matching_Manufacturer_rows = matching_Manufacturer_rows.assign(index_id=index)\n",
    "            temp_df = temp_df.append(matching_Manufacturer_rows)\n",
    "\n",
    "\n",
    "        # 每次循环结束后，对temp_df按照'fuzz_ratio'降序排序，然后添加到matched_df中\n",
    "        if 'fuzz_ratio' in temp_df.columns:\n",
    "            temp_df = temp_df.sort_values(by='fuzz_ratio', ascending=False)\n",
    "            matched_df = matched_df.append(temp_df)\n",
    "\n",
    "        # 将每个min1对应的fuzz_ratio最高的行添加到highest_ratio_df中\n",
    "        if max_ratio_row is not None:\n",
    "            highest_ratio_df = highest_ratio_df.append(max_ratio_row)\n",
    "    return matched_df,highest_ratio_df\n",
    "# 打印最终得到的匹配结果\n",
    "# print(matched_df)\n",
    "# print(highest_ratio_df)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9068beaa27b1717c309acb10300fb2603990c09df67c94bbef42553159f9e1a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 64-bit ('test': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
